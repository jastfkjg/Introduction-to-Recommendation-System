# Classic Recommendation Model

## 协同过滤

### userCF
共现矩阵中的行向量代表相应用户的用户向量，通过计算两用户向量的相似度（余弦相似度，皮尔逊相似度）来得到与某一用户最相似的n个用户，再利用用户相似度与相似用户对该商品评价的加权平均获得目标用户的评价预测。

缺点：
1. 需要维护用户相似度矩阵，而用户数通常远大于商品数，导致用户相似度矩阵存储开销很大。
2. 用户历史数据向量往往非常稀疏，不适合一些获取反馈较困难的场景。

### itemCF
通过计算共现矩阵两两列向量（即物品向量）之间的相似性，构建物品相似度矩阵。针对用户历史行为中正反馈的物品，找出相似top k的物品。

userCF 和 itemCF：
1. userCF 具有更强的社交特性，有发现热点，跟踪热点的趋势，适用于新闻推荐场景。
2. itemCF 更适用于兴趣变化较为稳定的场景。

CF缺陷：
1. 热门商品有很强的头部效应，与大量商品产生相似性。
2. 处理稀疏向量能力弱，导致尾部商品很少被推荐。
3. 无法引入其他信息，如用户性别，年龄，商品类别，价格，上下文特征等。
   
### 矩阵分解
矩阵分解再协同过滤的共现矩阵基础上，引入了隐向量概念，加强了模型处理稀疏矩阵的能力。

矩阵分解将为每一个用户和物品生成一个隐向量，距离相近的物品向量推荐给用户。而用户和物品的隐向量是通过分解协同过滤的共现矩阵得到的。

对矩阵进行分解的方法有三种：
1. 特征值分解：只能用于方阵，这里不适用。
2. 奇异值分解
3. 梯度下降

奇异值分解可以解决矩阵分解问题，但存在一些缺陷：
1. 奇异值分解要求原始矩阵是稠密的。
2. 奇异值分解计算复杂度很高。

因此，奇异值分解并不适用于大规模的矩阵分解问题。因此，梯度下降成了矩阵分解的主要方法。（主要通过让原始评分$r_ui$与用户向量和物品向量之积$q_i^Tp_u$的差值最小。）

矩阵分解的优点和缺陷：
1. 泛化能力强：一定程度上解决了数据稀疏问题。
2. 空间复杂度低，不需要存储庞大的用户相似性矩阵或物品相似性矩阵。
3. 与深度学习的embedding思想相似，方便与深度网络结合。
4. 但同样不方便引入其他用户，物品，上下文特征。

## 逻辑回归



