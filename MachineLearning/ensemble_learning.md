# Ensemble Learning

## 1. Boosting

Boosting 训练基分类器采用串行方式，各个基分类器之间有依赖。

将分类器层层叠加，每一层训练时对前一层分类器分错的样本给予更高的权重。测试时，根据各层分类器的结果加权得到最终结果。

Boosting方法通过聚焦于基分类器分错的样本，减少集成分类器的偏差。

### 1.1 Adaboost




## 2. Bagging

Bagging方法在训练过程中各个基分类器无强依赖，可以并行训练。为了让基分类器之间互相独立，通常将训练集分为若干子集。

Bagging通过对训练样本进行多次采样，训练不同的模型来减少集成分类器的方差。

### 2.1 Random Forest